{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link: https://www.kaggle.com/kswamy15/mercari-using-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.extmath import density\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/mercari/train.tsv', sep='\\t')\n",
    "test_df = pd.read_csv('data/mercari/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train columns with null values:\\n', train_df.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "\n",
    "print('Test/Validation columns with null values:\\n', test_df.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "\n",
    "train_df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate how much of the brand names are not there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(632682/train_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 50% is not there hence we should probably not consider this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['brand_name'], axis=1)\n",
    "test_df = test_df.drop(['brand_name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check how many categories there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "frames = [train_df, test_df]\n",
    "combined_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_cat_df = combined_df['category_name']\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: pass\n",
    "\n",
    "combined_cat_df = combined_cat_df.apply(lambda x: split_cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def no_of_cats(cat_list):\n",
    "    try: return len(cat_list)\n",
    "    except: return 0\n",
    "    \n",
    "no_of_cats = pd.DataFrame(combined_cat_df.apply(lambda x: no_of_cats(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_of_cats['category_name'].max(axis=1)\n",
    "index_whr_max_categories = no_of_cats['category_name'].argmax()\n",
    "print(index_whr_max_categories)\n",
    "max_num_of_categories = len(split_cat(combined_df.iloc[[index_whr_max_categories]]['category_name'].tolist()[0]))\n",
    "print('there are a maximum of {} categories and this is happened in row:'.format(max_num_of_categories))\n",
    "combined_df.iloc[[index_whr_max_categories]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_cat(text, max_num_of_categories):\n",
    "    return_val = [\"None\"] * max_num_of_categories\n",
    "    try:\n",
    "        text_list = text.split(\"/\") + return_val\n",
    "        return text_list[:max_num_of_categories]\n",
    "    except:\n",
    "        return return_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the category name for train and test and total dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['category_name'] = train_df['category_name'].apply(lambda x: split_cat(x, max_num_of_categories))\n",
    "test_df['category_name'] = test_df['category_name'].apply(lambda x: split_cat(x, max_num_of_categories))\n",
    "combined_df['category_name'] = combined_df['category_name'].apply(lambda x: split_cat(x, max_num_of_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we know that there are 5 categories so we will try to find the unknown ones category per category. so we will make predictions based on the 5 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running category encoding on the first category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_cat1_list = [x[0] for x in combined_df['category_name'].tolist()]\n",
    "combined_cat1_list = [x for x in combined_cat1_list if not x == 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1_le = LabelEncoder()\n",
    "cat1_le.fit(combined_cat1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1_le.transform(['Men', 'Electronics', 'Women', 'Home', 'Women'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1_le.inverse_transform([5, 1, 9, 3, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we are able to build a label encoder state space for the first category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_catname_cat1(le, catlist):\n",
    "    try:\n",
    "        return le.transform(catlist[:1])[0]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['category_name'] = train_df['category_name'].apply(lambda x: convert_catname_cat1(cat1_le, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are some null values in item description so will need to make fill them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['item_description'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['item_description'] = train_df['item_description'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['item_description'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No null values in item description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_list = ['iPhone']\n",
    "train_df[train_df.name.isin(value_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the missing category names we should try to find some unsupervised learning so that some amount filling of the data should be present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running NLP on the categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will first try to classify the documents and see if we can get some meaningful classification based on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to use only the name to predict the category name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will drop all the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "category_df = deepcopy(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_df = category_df.drop(['train_id', 'item_condition_id', 'price', 'shipping'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category_df = category_df[pd.isnull(category_df['category_name'])]\n",
    "train_test_categry_df = category_df[pd.notnull(category_df['category_name'])]\n",
    "train_categry_df, test_categry_df = train_test_split(train_test_categry_df, test_size=0.2, random_state=42)\n",
    "print('separated into predict, train and test')\n",
    "print(category_df.shape, predict_category_df.shape, train_categry_df.shape, test_categry_df.shape)\n",
    "print(predict_category_df.shape[0] + train_categry_df.shape[0] + test_categry_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_category_df = train_categry_df[['name', 'item_description']]\n",
    "y_train_category_df = train_categry_df[['category_name']]\n",
    "X_test_category_df = test_categry_df[['name', 'item_description']]\n",
    "y_test_category_df = test_categry_df[['category_name']]\n",
    "print('separate to x and y')\n",
    "print(X_train_category_df.shape, y_train_category_df.shape, X_test_category_df.shape, y_test_category_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_category_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Combine the name and item_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_category_df['total_text'] = X_train_category_df['name'] + \" \" +  X_train_category_df['item_description']\n",
    "X_train_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_category_df['total_text'] = X_test_category_df['name'] + \" \" +  X_test_category_df['item_description']\n",
    "X_test_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extracting features from the training data using a sparse vectorizer')\n",
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "x_train = vectorizer.fit_transform(X_train_category_df['total_text'])\n",
    "duration = time() - t0\n",
    "print(\"done in %fs\" % (duration))    \n",
    "print(\"n_samples: %d, n_features: %d\" % x_train.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extracting features from the testing data using a sparse vectorizer')\n",
    "t0 = time()\n",
    "x_test = vectorizer.transform(X_test_category_df['total_text'])\n",
    "duration = time() - t0\n",
    "print(\"done in %fs\" % (duration))    \n",
    "print(\"n_samples: %d, n_features: %d\" % x_train.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #############################################################################  \n",
    "# Benchmark classifiers                                                          \n",
    "def benchmark(clf, X_train, y_train, X_test, y_test, target_names):                                                              \n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "                                                                                 \n",
    "    if hasattr(clf, 'coef_'):                                                    \n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "                                                                                 \n",
    "        if feature_names is not None:                       \n",
    "            print(\"top 10 keywords per class:\")                                  \n",
    "            for i, label in enumerate(target_names):                             \n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "                                                                                 \n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred, target_names=target_names))          \n",
    "                                                                                 \n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))                            \n",
    "                                                                                 \n",
    "    print()                                                                      \n",
    "    clf_descr = str(clf).split('(')[0]                                           \n",
    "    return clf_descr, score, train_time, test_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []                                                                     \n",
    "for clf, name in (                                                            \n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),          \n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),                                   \n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),          \n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),                           \n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):            \n",
    "    print('=' * 80)                                                              \n",
    "    print(name)                                                                  \n",
    "    results.append(benchmark(clf, x_train, y_train_category_df, x_test, y_test_category_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_category_df = category_df[['name', 'item_description']]\n",
    "y_category_df = category_df[['category_name']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
