{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "links: https://youtu.be/BhpvH5DuVu8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-d651cc53d7d8>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/joydeep/roam/analysis_notebooks/experiments/develop/2018-07-17-Neo4j-Fetch_Edges-and-Nodes/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/joydeep/roam/analysis_notebooks/experiments/develop/2018-07-17-Neo4j-Fetch_Edges-and-Nodes/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/joydeep/roam/analysis_notebooks/experiments/develop/2018-07-17-Neo4j-Fetch_Edges-and-Nodes/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/joydeep/roam/analysis_notebooks/experiments/develop/2018-07-17-Neo4j-Fetch_Edges-and-Nodes/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/joydeep/roam/analysis_notebooks/experiments/develop/2018-07-17-Neo4j-Fetch_Edges-and-Nodes/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(data):\n",
    "    hidden_1_layer = {'weights': tf.Variable(tf.random_normal([784, n_nodes_hl1])), \n",
    "                      'biases': tf.Variable(tf.random_normal([n_nodes_hl1]))} \n",
    "    hidden_2_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2 ])), \n",
    "                      'biases': tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    hidden_3_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])), \n",
    "                      'biases': tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    output_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])), \n",
    "                    'biases': tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    layer1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    \n",
    "    layer2 = tf.add(tf.matmul(layer1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    \n",
    "    layer3 = tf.add(tf.matmul(layer2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    layer3 = tf.nn.relu(layer3)\n",
    "    \n",
    "    output = tf.matmul(layer3, output_layer['weights']) + output_layer['biases']\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_num_examples = len(_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    prediction = neural_network(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    how_many_epochs = 100\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(how_many_epochs):\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epock_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                _, c = sess.run([optimizer, cost], feed_dict= {x: epock_x, y: epoch_y})\n",
    "            \n",
    "            epoch_loss += c\n",
    "            \n",
    "            print('Epoch', epoch, 'completed out of', how_many_epochs, 'loss', epoch_loss)\n",
    "            \n",
    "        correct = tf.equal(tf.arg_max(prediction, 1), tf.arg_max(y, 1))\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy', accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 100 loss 1518.60693359375\n",
      "Epoch 1 completed out of 100 loss 403.6920166015625\n",
      "Epoch 2 completed out of 100 loss 493.5411071777344\n",
      "Epoch 3 completed out of 100 loss 229.49021911621094\n",
      "Epoch 4 completed out of 100 loss 104.87151336669922\n",
      "Epoch 5 completed out of 100 loss 68.40415954589844\n",
      "Epoch 6 completed out of 100 loss 0.0\n",
      "Epoch 7 completed out of 100 loss 9.032890319824219\n",
      "Epoch 8 completed out of 100 loss 79.80950927734375\n",
      "Epoch 9 completed out of 100 loss 0.0\n",
      "Epoch 10 completed out of 100 loss 0.0\n",
      "Epoch 11 completed out of 100 loss 0.0\n",
      "Epoch 12 completed out of 100 loss 3.481250047683716\n",
      "Epoch 13 completed out of 100 loss 2.619687557220459\n",
      "Epoch 14 completed out of 100 loss 21.201757431030273\n",
      "Epoch 15 completed out of 100 loss 42.618438720703125\n",
      "Epoch 16 completed out of 100 loss 2.7165820598602295\n",
      "Epoch 17 completed out of 100 loss 66.87228393554688\n",
      "Epoch 18 completed out of 100 loss 4.612109184265137\n",
      "Epoch 19 completed out of 100 loss 0.0\n",
      "Epoch 20 completed out of 100 loss 0.0\n",
      "Epoch 21 completed out of 100 loss 0.0\n",
      "Epoch 22 completed out of 100 loss 0.0\n",
      "Epoch 23 completed out of 100 loss 12.648906707763672\n",
      "Epoch 24 completed out of 100 loss 0.0\n",
      "Epoch 25 completed out of 100 loss 0.0\n",
      "Epoch 26 completed out of 100 loss 0.0\n",
      "Epoch 27 completed out of 100 loss 0.0\n",
      "Epoch 28 completed out of 100 loss 0.0\n",
      "Epoch 29 completed out of 100 loss 10.078085899353027\n",
      "Epoch 30 completed out of 100 loss 0.0\n",
      "Epoch 31 completed out of 100 loss 18.970117568969727\n",
      "Epoch 32 completed out of 100 loss 4.299667835235596\n",
      "Epoch 33 completed out of 100 loss 0.0\n",
      "Epoch 34 completed out of 100 loss 0.0\n",
      "Epoch 35 completed out of 100 loss 0.0\n",
      "Epoch 36 completed out of 100 loss 0.0\n",
      "Epoch 37 completed out of 100 loss 0.6742773652076721\n",
      "Epoch 38 completed out of 100 loss 0.0\n",
      "Epoch 39 completed out of 100 loss 0.0\n",
      "Epoch 40 completed out of 100 loss 68.21156311035156\n",
      "Epoch 41 completed out of 100 loss 0.0\n",
      "Epoch 42 completed out of 100 loss 5.596367359161377\n",
      "Epoch 43 completed out of 100 loss 0.0\n",
      "Epoch 44 completed out of 100 loss 0.0\n",
      "Epoch 45 completed out of 100 loss 8.834375381469727\n",
      "Epoch 46 completed out of 100 loss 0.0\n",
      "Epoch 47 completed out of 100 loss 2.849980354309082\n",
      "Epoch 48 completed out of 100 loss 0.0\n",
      "Epoch 49 completed out of 100 loss 0.0\n",
      "Epoch 50 completed out of 100 loss 0.0\n",
      "Epoch 51 completed out of 100 loss 86.18862915039062\n",
      "Epoch 52 completed out of 100 loss 0.0\n",
      "Epoch 53 completed out of 100 loss 0.0\n",
      "Epoch 54 completed out of 100 loss 0.0\n",
      "Epoch 55 completed out of 100 loss 0.0\n",
      "Epoch 56 completed out of 100 loss 0.0\n",
      "Epoch 57 completed out of 100 loss 0.0\n",
      "Epoch 58 completed out of 100 loss 0.0\n",
      "Epoch 59 completed out of 100 loss 0.0\n",
      "Epoch 60 completed out of 100 loss 0.0\n",
      "Epoch 61 completed out of 100 loss 66.8565444946289\n",
      "Epoch 62 completed out of 100 loss 45.10639572143555\n",
      "Epoch 63 completed out of 100 loss 2.765617352906702e-07\n",
      "Epoch 64 completed out of 100 loss 0.0\n",
      "Epoch 65 completed out of 100 loss 0.0\n",
      "Epoch 66 completed out of 100 loss 0.0\n",
      "Epoch 67 completed out of 100 loss 0.0\n",
      "Epoch 68 completed out of 100 loss 0.0\n",
      "Epoch 69 completed out of 100 loss 0.0\n",
      "Epoch 70 completed out of 100 loss 0.0\n",
      "Epoch 71 completed out of 100 loss 109.95109558105469\n",
      "Epoch 72 completed out of 100 loss 0.0\n",
      "Epoch 73 completed out of 100 loss 23.49835968017578\n",
      "Epoch 74 completed out of 100 loss 0.0\n",
      "Epoch 75 completed out of 100 loss 0.0\n",
      "Epoch 76 completed out of 100 loss 0.0\n",
      "Epoch 77 completed out of 100 loss 1.5522265434265137\n",
      "Epoch 78 completed out of 100 loss 0.0\n",
      "Epoch 79 completed out of 100 loss 19.353710174560547\n",
      "Epoch 80 completed out of 100 loss 0.0\n",
      "Epoch 81 completed out of 100 loss 0.0\n",
      "Epoch 82 completed out of 100 loss 0.0\n",
      "Epoch 83 completed out of 100 loss 0.0\n",
      "Epoch 84 completed out of 100 loss 0.0\n",
      "Epoch 85 completed out of 100 loss 0.0\n",
      "Epoch 86 completed out of 100 loss 0.0\n",
      "Epoch 87 completed out of 100 loss 0.0\n",
      "Epoch 88 completed out of 100 loss 0.0\n",
      "Epoch 89 completed out of 100 loss 30.2401180267334\n",
      "Epoch 90 completed out of 100 loss 0.0\n",
      "Epoch 91 completed out of 100 loss 0.0\n",
      "Epoch 92 completed out of 100 loss 0.0\n",
      "Epoch 93 completed out of 100 loss 35.56511688232422\n",
      "Epoch 94 completed out of 100 loss 0.0\n",
      "Epoch 95 completed out of 100 loss 41.290313720703125\n",
      "Epoch 96 completed out of 100 loss 0.0\n",
      "Epoch 97 completed out of 100 loss 0.0\n",
      "Epoch 98 completed out of 100 loss 0.0\n",
      "Epoch 99 completed out of 100 loss 16.0322265625\n",
      "WARNING:tensorflow:From <ipython-input-17-39322ea307d9>:23: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "Accuracy 0.9727\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
