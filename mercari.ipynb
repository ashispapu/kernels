{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/mercari/train.tsv', sep='\\t')\n",
    "test_df = pd.read_csv('data/mercari/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.482535e+06</td>\n",
       "      <td>1.482535e+06</td>\n",
       "      <td>1.482535e+06</td>\n",
       "      <td>1.482535e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.412670e+05</td>\n",
       "      <td>1.907380e+00</td>\n",
       "      <td>2.673752e+01</td>\n",
       "      <td>4.472744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.279711e+05</td>\n",
       "      <td>9.031586e-01</td>\n",
       "      <td>3.858607e+01</td>\n",
       "      <td>4.972124e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.706335e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.412670e+05</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.111900e+06</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482534e+06</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_id  item_condition_id         price      shipping\n",
       "count  1.482535e+06       1.482535e+06  1.482535e+06  1.482535e+06\n",
       "mean   7.412670e+05       1.907380e+00  2.673752e+01  4.472744e-01\n",
       "std    4.279711e+05       9.031586e-01  3.858607e+01  4.972124e-01\n",
       "min    0.000000e+00       1.000000e+00  0.000000e+00  0.000000e+00\n",
       "25%    3.706335e+05       1.000000e+00  1.000000e+01  0.000000e+00\n",
       "50%    7.412670e+05       2.000000e+00  1.700000e+01  0.000000e+00\n",
       "75%    1.111900e+06       3.000000e+00  2.900000e+01  1.000000e+00\n",
       "max    1.482534e+06       5.000000e+00  2.009000e+03  1.000000e+00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482535, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns with null values:\n",
      " train_id                  0\n",
      "name                      0\n",
      "item_condition_id         0\n",
      "category_name          6327\n",
      "brand_name           632682\n",
      "price                     0\n",
      "shipping                  0\n",
      "item_description          4\n",
      "dtype: int64\n",
      "----------\n",
      "Test/Validation columns with null values:\n",
      " test_id                   0\n",
      "name                      0\n",
      "item_condition_id         0\n",
      "category_name          3058\n",
      "brand_name           295525\n",
      "shipping                  0\n",
      "item_description          0\n",
      "dtype: int64\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.482535e+06</td>\n",
       "      <td>1482535</td>\n",
       "      <td>1.482535e+06</td>\n",
       "      <td>1476208</td>\n",
       "      <td>849853</td>\n",
       "      <td>1.482535e+06</td>\n",
       "      <td>1.482535e+06</td>\n",
       "      <td>1482531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1225273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1287</td>\n",
       "      <td>4809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1281426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bundle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Women/Athletic Apparel/Pants, Tights, Leggings</td>\n",
       "      <td>PINK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60177</td>\n",
       "      <td>54088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.412670e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.907380e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.673752e+01</td>\n",
       "      <td>4.472744e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.279711e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.031586e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.858607e+01</td>\n",
       "      <td>4.972124e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.706335e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.412670e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.111900e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482534e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_id     name  item_condition_id  \\\n",
       "count   1.482535e+06  1482535       1.482535e+06   \n",
       "unique           NaN  1225273                NaN   \n",
       "top              NaN   Bundle                NaN   \n",
       "freq             NaN     2232                NaN   \n",
       "mean    7.412670e+05      NaN       1.907380e+00   \n",
       "std     4.279711e+05      NaN       9.031586e-01   \n",
       "min     0.000000e+00      NaN       1.000000e+00   \n",
       "25%     3.706335e+05      NaN       1.000000e+00   \n",
       "50%     7.412670e+05      NaN       2.000000e+00   \n",
       "75%     1.111900e+06      NaN       3.000000e+00   \n",
       "max     1.482534e+06      NaN       5.000000e+00   \n",
       "\n",
       "                                         category_name brand_name  \\\n",
       "count                                          1476208     849853   \n",
       "unique                                            1287       4809   \n",
       "top     Women/Athletic Apparel/Pants, Tights, Leggings       PINK   \n",
       "freq                                             60177      54088   \n",
       "mean                                               NaN        NaN   \n",
       "std                                                NaN        NaN   \n",
       "min                                                NaN        NaN   \n",
       "25%                                                NaN        NaN   \n",
       "50%                                                NaN        NaN   \n",
       "75%                                                NaN        NaN   \n",
       "max                                                NaN        NaN   \n",
       "\n",
       "               price      shipping    item_description  \n",
       "count   1.482535e+06  1.482535e+06             1482531  \n",
       "unique           NaN           NaN             1281426  \n",
       "top              NaN           NaN  No description yet  \n",
       "freq             NaN           NaN               82489  \n",
       "mean    2.673752e+01  4.472744e-01                 NaN  \n",
       "std     3.858607e+01  4.972124e-01                 NaN  \n",
       "min     0.000000e+00  0.000000e+00                 NaN  \n",
       "25%     1.000000e+01  0.000000e+00                 NaN  \n",
       "50%     1.700000e+01  0.000000e+00                 NaN  \n",
       "75%     2.900000e+01  1.000000e+00                 NaN  \n",
       "max     2.009000e+03  1.000000e+00                 NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train columns with null values:\\n', train_df.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "\n",
    "print('Test/Validation columns with null values:\\n', test_df.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "\n",
    "train_df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate how much of the brand names are not there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4267568725190299\n"
     ]
    }
   ],
   "source": [
    "print(632682/train_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 50% is not there hence we should probably not consider this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['brand_name'], axis=1)\n",
    "test_df = test_df.drop(['brand_name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check how many categories there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "frames = [train_df, test_df]\n",
    "combined_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_cat_df = combined_df['category_name']\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: pass\n",
    "\n",
    "combined_cat_df = combined_cat_df.apply(lambda x: split_cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def no_of_cats(cat_list):\n",
    "    try: return len(cat_list)\n",
    "    except: return 0\n",
    "    \n",
    "no_of_cats = pd.DataFrame(combined_cat_df.apply(lambda x: no_of_cats(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "there are a maximum of 5 categories and this is happened in row:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Electronics/Computers &amp; Tablets/iPad/Tablet/eB...</td>\n",
       "      <td>1</td>\n",
       "      <td>Zag invisible shield for IPad air</td>\n",
       "      <td>Zagg invisible shield for IPad air</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         category_name  item_condition_id  \\\n",
       "239  Electronics/Computers & Tablets/iPad/Tablet/eB...                  1   \n",
       "\n",
       "                      item_description                                name  \\\n",
       "239  Zag invisible shield for IPad air  Zagg invisible shield for IPad air   \n",
       "\n",
       "     price  shipping  test_id  train_id  \n",
       "239   10.0         1      NaN     239.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no_of_cats['category_name'].max(axis=1)\n",
    "index_whr_max_categories = no_of_cats['category_name'].argmax()\n",
    "print(index_whr_max_categories)\n",
    "max_num_of_categories = len(split_cat(combined_df.iloc[[index_whr_max_categories]]['category_name'].tolist()[0]))\n",
    "print('there are a maximum of {} categories and this is happened in row:'.format(max_num_of_categories))\n",
    "combined_df.iloc[[index_whr_max_categories]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def split_cat(text, max_num_of_categories):\n",
    "#     return_val = [\"None\"] * max_num_of_categories\n",
    "#     try:\n",
    "#         text_list = text.split(\"/\") + return_val\n",
    "#         return text_list[:max_num_of_categories]\n",
    "#     except:\n",
    "#         return return_val\n",
    "    \n",
    "def split_cat(text):\n",
    "    try:\n",
    "        text_list = text.split(\"/\")\n",
    "        return text_list\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the category name for train and test and total dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_df['category_name'] = train_df['category_name'].apply(lambda x: split_cat(x, max_num_of_categories))\n",
    "# test_df['category_name'] = test_df['category_name'].apply(lambda x: split_cat(x, max_num_of_categories))\n",
    "# combined_df['category_name'] = combined_df['category_name'].apply(lambda x: split_cat(x, max_num_of_categories))\n",
    "\n",
    "train_df['category_name'] = train_df['category_name'].apply(lambda x: split_cat(x))\n",
    "test_df['category_name'] = test_df['category_name'].apply(lambda x: split_cat(x))\n",
    "combined_df['category_name'] = combined_df['category_name'].apply(lambda x: split_cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>[Men, Tops, T-shirts]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>[Electronics, Computers &amp; Tablets, Components ...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>[Women, Tops &amp; Blouses, Blouse]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>[Home, Home Décor, Home Décor Accents]</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>[Women, Jewelry, Necklaces]</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name  price  shipping  \\\n",
       "0                              [Men, Tops, T-shirts]   10.0         1   \n",
       "1  [Electronics, Computers & Tablets, Components ...   52.0         0   \n",
       "2                    [Women, Tops & Blouses, Blouse]   10.0         1   \n",
       "3             [Home, Home Décor, Home Décor Accents]   35.0         1   \n",
       "4                        [Women, Jewelry, Necklaces]   44.0         0   \n",
       "\n",
       "                                    item_description  \n",
       "0                                 No description yet  \n",
       "1  This keyboard is in great condition and works ...  \n",
       "2  Adorable top with a hint of lace and a key hol...  \n",
       "3  New with tags. Leather horses. Retail for [rm]...  \n",
       "4          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we know that there are 5 categories so we will try to find the unknown ones category per category. so we will make predictions based on the 5 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling a list of categories and classifying them as category1, category2 and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resolve_item(item, index):\n",
    "    try:\n",
    "        return item[index]\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    \n",
    "def resolve_null_value(item, null_value):\n",
    "    if item == null_value:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return item\n",
    "\n",
    "    \n",
    "def replace_null_value(df, le, category_name, nullity=''):\n",
    "    null_value = le.transform([nullity])[0]\n",
    "    return df[category_name].apply(lambda x: resolve_null_value(x, null_value))\n",
    "\n",
    "\n",
    "def label_encoding_transform(target_df, combined_df, max_num_of_categories):\n",
    "    category_transforms = []\n",
    "    for i in range(max_num_of_categories):\n",
    "        combined_cat_list = [resolve_item(x, i) for x in combined_df['category_name'].tolist()]\n",
    "        \n",
    "        cat_le = LabelEncoder()\n",
    "        cat_le.fit(combined_cat_list)\n",
    "        \n",
    "        category_name = 'category_{}'.format(i)\n",
    "        \n",
    "        target_df[category_name] = cat_le.transform(target_df['category_name'].apply(lambda x: resolve_item(x, i)))\n",
    "        \n",
    "        # replace null value\n",
    "        target_df[category_name] = replace_null_value(target_df, cat_le, category_name)\n",
    "        category_transforms.append(cat_le)\n",
    "    return target_df, category_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>[Men, Tops, T-shirts]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>6.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>[Electronics, Computers &amp; Tablets, Components ...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>[Women, Tops &amp; Blouses, Blouse]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>[Home, Home Décor, Home Décor Accents]</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>[Women, Jewelry, Necklaces]</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name  price  shipping  \\\n",
       "0                              [Men, Tops, T-shirts]   10.0         1   \n",
       "1  [Electronics, Computers & Tablets, Components ...   52.0         0   \n",
       "2                    [Women, Tops & Blouses, Blouse]   10.0         1   \n",
       "3             [Home, Home Décor, Home Décor Accents]   35.0         1   \n",
       "4                        [Women, Jewelry, Necklaces]   44.0         0   \n",
       "\n",
       "                                    item_description  category_0  category_1  \\\n",
       "0                                 No description yet         6.0       103.0   \n",
       "1  This keyboard is in great condition and works ...         2.0        31.0   \n",
       "2  Adorable top with a hint of lace and a key hol...        10.0       104.0   \n",
       "3  New with tags. Leather horses. Retail for [rm]...         4.0        56.0   \n",
       "4          Complete with certificate of authenticity        10.0        59.0   \n",
       "\n",
       "   category_2  category_3  category_4  \n",
       "0       774.0         NaN         NaN  \n",
       "1       216.0         NaN         NaN  \n",
       "2        98.0         NaN         NaN  \n",
       "3       411.0         NaN         NaN  \n",
       "4       543.0         NaN         NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, train_cat_transforms = label_encoding_transform(train_df, combined_df, max_num_of_categories)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Breast cancer \"I fight like a girl\" ring</td>\n",
       "      <td>1</td>\n",
       "      <td>[Women, Jewelry, Rings]</td>\n",
       "      <td>1</td>\n",
       "      <td>Size 7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers</td>\n",
       "      <td>1</td>\n",
       "      <td>[Other, Office supplies, Shipping Supplies]</td>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>[Vintage &amp; Collectibles, Bags and Purses, Hand...</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new coach bag. Bought for [rm] at a Coac...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Floral Kimono</td>\n",
       "      <td>2</td>\n",
       "      <td>[Women, Sweaters, Cardigan]</td>\n",
       "      <td>0</td>\n",
       "      <td>-floral kimono -never worn -lightweight and pe...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Life after Death</td>\n",
       "      <td>3</td>\n",
       "      <td>[Other, Books, Religion &amp; Spirituality]</td>\n",
       "      <td>1</td>\n",
       "      <td>Rediscovering life after the loss of a loved o...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                      name  item_condition_id  \\\n",
       "0        0  Breast cancer \"I fight like a girl\" ring                  1   \n",
       "1        1  25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers                  1   \n",
       "2        2                                 Coach bag                  1   \n",
       "3        3                             Floral Kimono                  2   \n",
       "4        4                          Life after Death                  3   \n",
       "\n",
       "                                       category_name  shipping  \\\n",
       "0                            [Women, Jewelry, Rings]         1   \n",
       "1        [Other, Office supplies, Shipping Supplies]         1   \n",
       "2  [Vintage & Collectibles, Bags and Purses, Hand...         1   \n",
       "3                        [Women, Sweaters, Cardigan]         0   \n",
       "4            [Other, Books, Religion & Spirituality]         1   \n",
       "\n",
       "                                    item_description  category_0  category_1  \\\n",
       "0                                             Size 7        10.0        59.0   \n",
       "1  25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...         7.0        72.0   \n",
       "2  Brand new coach bag. Bought for [rm] at a Coac...         9.0         8.0   \n",
       "3  -floral kimono -never worn -lightweight and pe...        10.0        97.0   \n",
       "4  Rediscovering life after the loss of a loved o...         7.0        15.0   \n",
       "\n",
       "   category_2  category_3  category_4  \n",
       "0       667.0         NaN         NaN  \n",
       "1       701.0         NaN         NaN  \n",
       "2       383.0         NaN         NaN  \n",
       "3       167.0         NaN         NaN  \n",
       "4       662.0         NaN         NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df, test_cat_transforms = label_encoding_transform(test_df, combined_df, max_num_of_categories)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are some null values in item description so will need to make fill them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presently number of null values in train and test.\n",
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('presently number of null values in train and test.')\n",
    "print(train_df['item_description'].isnull().sum())\n",
    "print(test_df['item_description'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of null values in item description is for training set is 0.\n",
      "Num of null values in item description is for test set is 0.\n",
      "Ideally this number should be 0.\n"
     ]
    }
   ],
   "source": [
    "train_df['item_description'] = train_df['item_description'].fillna(\"\")\n",
    "test_df['item_description'] = test_df['item_description'].fillna(\"\")\n",
    "print('Num of null values in item description is for training set is {}.'.format(train_df['item_description'].isnull().sum()))\n",
    "print('Num of null values in item description is for test set is {}.'.format(test_df['item_description'].isnull().sum()))\n",
    "print('Ideally this number should be 0.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>[Men, Tops, T-shirts]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>6.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>[Electronics, Computers &amp; Tablets, Components ...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>[Women, Tops &amp; Blouses, Blouse]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>[Home, Home Décor, Home Décor Accents]</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>[Women, Jewelry, Necklaces]</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name  price  shipping  \\\n",
       "0                              [Men, Tops, T-shirts]   10.0         1   \n",
       "1  [Electronics, Computers & Tablets, Components ...   52.0         0   \n",
       "2                    [Women, Tops & Blouses, Blouse]   10.0         1   \n",
       "3             [Home, Home Décor, Home Décor Accents]   35.0         1   \n",
       "4                        [Women, Jewelry, Necklaces]   44.0         0   \n",
       "\n",
       "                                    item_description  category_0  category_1  \\\n",
       "0                                 No description yet         6.0       103.0   \n",
       "1  This keyboard is in great condition and works ...         2.0        31.0   \n",
       "2  Adorable top with a hint of lace and a key hol...        10.0       104.0   \n",
       "3  New with tags. Leather horses. Retail for [rm]...         4.0        56.0   \n",
       "4          Complete with certificate of authenticity        10.0        59.0   \n",
       "\n",
       "   category_2  category_3  category_4  \n",
       "0       774.0         NaN         NaN  \n",
       "1       216.0         NaN         NaN  \n",
       "2        98.0         NaN         NaN  \n",
       "3       411.0         NaN         NaN  \n",
       "4       543.0         NaN         NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Breast cancer \"I fight like a girl\" ring</td>\n",
       "      <td>1</td>\n",
       "      <td>[Women, Jewelry, Rings]</td>\n",
       "      <td>1</td>\n",
       "      <td>Size 7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers</td>\n",
       "      <td>1</td>\n",
       "      <td>[Other, Office supplies, Shipping Supplies]</td>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>[Vintage &amp; Collectibles, Bags and Purses, Hand...</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new coach bag. Bought for [rm] at a Coac...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Floral Kimono</td>\n",
       "      <td>2</td>\n",
       "      <td>[Women, Sweaters, Cardigan]</td>\n",
       "      <td>0</td>\n",
       "      <td>-floral kimono -never worn -lightweight and pe...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Life after Death</td>\n",
       "      <td>3</td>\n",
       "      <td>[Other, Books, Religion &amp; Spirituality]</td>\n",
       "      <td>1</td>\n",
       "      <td>Rediscovering life after the loss of a loved o...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                      name  item_condition_id  \\\n",
       "0        0  Breast cancer \"I fight like a girl\" ring                  1   \n",
       "1        1  25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers                  1   \n",
       "2        2                                 Coach bag                  1   \n",
       "3        3                             Floral Kimono                  2   \n",
       "4        4                          Life after Death                  3   \n",
       "\n",
       "                                       category_name  shipping  \\\n",
       "0                            [Women, Jewelry, Rings]         1   \n",
       "1        [Other, Office supplies, Shipping Supplies]         1   \n",
       "2  [Vintage & Collectibles, Bags and Purses, Hand...         1   \n",
       "3                        [Women, Sweaters, Cardigan]         0   \n",
       "4            [Other, Books, Religion & Spirituality]         1   \n",
       "\n",
       "                                    item_description  category_0  category_1  \\\n",
       "0                                             Size 7        10.0        59.0   \n",
       "1  25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...         7.0        72.0   \n",
       "2  Brand new coach bag. Bought for [rm] at a Coac...         9.0         8.0   \n",
       "3  -floral kimono -never worn -lightweight and pe...        10.0        97.0   \n",
       "4  Rediscovering life after the loss of a loved o...         7.0        15.0   \n",
       "\n",
       "   category_2  category_3  category_4  \n",
       "0       667.0         NaN         NaN  \n",
       "1       701.0         NaN         NaN  \n",
       "2       383.0         NaN         NaN  \n",
       "3       167.0         NaN         NaN  \n",
       "4       662.0         NaN         NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161166</th>\n",
       "      <td>161166</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1</td>\n",
       "      <td>[Electronics, Cell Phones &amp; Accessories, Cell ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Luxury 360° Hybrid Acrylic Hard Case Original ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331692</th>\n",
       "      <td>331692</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>2</td>\n",
       "      <td>[Electronics, Cell Phones &amp; Accessories, Cell ...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>iCloud lock!!! Screen protector no scratches! ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502203</th>\n",
       "      <td>502203</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>3</td>\n",
       "      <td>[Electronics, Cell Phones &amp; Accessories, Cell ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901734</th>\n",
       "      <td>901734</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1</td>\n",
       "      <td>[Electronics, Cell Phones &amp; Accessories, Cell ...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple iPhone headphones for iPhones compatible...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968525</th>\n",
       "      <td>968525</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>2</td>\n",
       "      <td>[Electronics, Cell Phones &amp; Accessories, Cell ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Two iPhone 4s they are locked so they are to b...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_id    name  item_condition_id  \\\n",
       "161166    161166  iPhone                  1   \n",
       "331692    331692  iPhone                  2   \n",
       "502203    502203  iPhone                  3   \n",
       "901734    901734  iPhone                  1   \n",
       "968525    968525  iPhone                  2   \n",
       "\n",
       "                                            category_name  price  shipping  \\\n",
       "161166  [Electronics, Cell Phones & Accessories, Cell ...    4.0         1   \n",
       "331692  [Electronics, Cell Phones & Accessories, Cell ...   76.0         0   \n",
       "502203  [Electronics, Cell Phones & Accessories, Cell ...   26.0         1   \n",
       "901734  [Electronics, Cell Phones & Accessories, Cell ...   17.0         1   \n",
       "968525  [Electronics, Cell Phones & Accessories, Cell ...   19.0         0   \n",
       "\n",
       "                                         item_description  category_0  \\\n",
       "161166  Luxury 360° Hybrid Acrylic Hard Case Original ...         2.0   \n",
       "331692  iCloud lock!!! Screen protector no scratches! ...         2.0   \n",
       "502203                                 No description yet         2.0   \n",
       "901734  Apple iPhone headphones for iPhones compatible...         2.0   \n",
       "968525  Two iPhone 4s they are locked so they are to b...         2.0   \n",
       "\n",
       "        category_1  category_2  category_3  category_4  \n",
       "161166        24.0       178.0         NaN         NaN  \n",
       "331692        24.0       179.0         NaN         NaN  \n",
       "502203        24.0       179.0         NaN         NaN  \n",
       "901734        24.0       179.0         NaN         NaN  \n",
       "968525        24.0       179.0         NaN         NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_list = ['iPhone']\n",
    "train_df[train_df.name.isin(value_list)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the missing category names we should try to find some unsupervised learning so that some amount filling of the data should be present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running NLP on the categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will first try to classify the documents and see if we can get some meaningful classification based on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to use only the name to predict the category name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will drop all the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_id', 'name', 'item_condition_id', 'category_name', 'price', 'shipping', 'item_description', 'category_0', 'category_1', 'category_2', 'category_3', 'category_4']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "category_df = deepcopy(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_df = category_df.drop(['train_id', 'item_condition_id', 'price', 'shipping'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117182</th>\n",
       "      <td>NWT Emmitt Smith Adult XXL jersey</td>\n",
       "      <td>[Men, Athletic Apparel, Jerseys]</td>\n",
       "      <td>Brand new with tags Stitched jersey Adult XXL ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902633</th>\n",
       "      <td>Rebecca Minkoff Apple Watch band 38 S/M</td>\n",
       "      <td>[Women, Women's Accessories, Watches]</td>\n",
       "      <td>NIP Apple Watch band 38mm S/M Black leather, c...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name  \\\n",
       "117182        NWT Emmitt Smith Adult XXL jersey   \n",
       "902633  Rebecca Minkoff Apple Watch band 38 S/M   \n",
       "\n",
       "                                category_name  \\\n",
       "117182       [Men, Athletic Apparel, Jerseys]   \n",
       "902633  [Women, Women's Accessories, Watches]   \n",
       "\n",
       "                                         item_description  category_0  \\\n",
       "117182  Brand new with tags Stitched jersey Adult XXL ...         6.0   \n",
       "902633  NIP Apple Watch band 38mm S/M Black leather, c...        10.0   \n",
       "\n",
       "        category_1  category_2  category_3  category_4  \n",
       "117182         6.0       445.0         NaN         NaN  \n",
       "902633       111.0       861.0         NaN         NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict_category_df = category_df[pd.isnull(category_df['category_name'])]\n",
    "# train_test_categry_df = category_df[pd.notnull(category_df['category_name'])]\n",
    "# train_categry_df, test_categry_df = train_test_split(train_test_categry_df, test_size=0.2, random_state=42)\n",
    "# print('separated into predict, train and test')\n",
    "# print(category_df.shape, predict_category_df.shape, train_categry_df.shape, test_categry_df.shape)\n",
    "# print(predict_category_df.shape[0] + train_categry_df.shape[0] + test_categry_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_train_test(category_df, category_name):\n",
    "    predict_category_df = category_df[pd.isnull(category_df[category_name])]\n",
    "    train_test_categry_df = category_df[pd.notnull(category_df[category_name])]\n",
    "    train_categry_df, test_categry_df = train_test_split(train_test_categry_df, test_size=0.2, random_state=42)\n",
    "    return dict(predict_category_df=predict_category_df, \n",
    "                train_categry_df=train_categry_df, \n",
    "                test_categry_df=test_categry_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_train_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_train_test_dict['category_0'] = predict_train_test(category_df, 'category_0')\n",
    "predict_train_test_dict['category_1'] = predict_train_test(category_df, 'category_1')\n",
    "predict_train_test_dict['category_2'] = predict_train_test(category_df, 'category_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_category_df = train_categry_df[['name', 'item_description']]\n",
    "# y_train_category_df = train_categry_df[['category_0']]\n",
    "# X_test_category_df = test_categry_df[['name', 'item_description']]\n",
    "# y_test_category_df = test_categry_df[['category_0']]\n",
    "# print('separate to x and y')\n",
    "# print(X_train_category_df.shape, y_train_category_df.shape, X_test_category_df.shape, y_test_category_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_category_df_list = [df['train_categry_df'][['name', 'item_description']] for cat, df in predict_train_test_dict.items()]\n",
    "y_train_category_df_list = [df['train_categry_df'][[cat]] for cat, df in predict_train_test_dict.items()]\n",
    "X_test_category_df_list = [df['test_categry_df'][['name', 'item_description']] for cat, df in predict_train_test_dict.items()]\n",
    "y_test_category_df_list = [df['test_categry_df'][[cat]] for cat, df in predict_train_test_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('separate to x and y')\n",
    "print(X_train_category_df_list[0].shape, y_train_category_df_list[0].shape, X_test_category_df_list[0].shape, y_test_category_df_list[0].shape)\n",
    "print(X_train_category_df_list[1].shape, y_train_category_df_list[1].shape, X_test_category_df_list[1].shape, y_test_category_df_list[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_category_df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_category_df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_cats = len(X_train_category_df_list)\n",
    "for i in range(number_of_cats):\n",
    "    X_train_category_df_list[i]['total_text'] = (\n",
    "        X_train_category_df_list[i]['name'] \n",
    "        + \" \" \n",
    "        +  X_train_category_df_list[i]['item_description']\n",
    "    )\n",
    "    \n",
    "    X_test_category_df_list[i]['total_text'] = (\n",
    "        X_test_category_df_list[i]['name'] \n",
    "        + \" \" +  X_test_category_df_list[i]['item_description']\n",
    "    )\n",
    "\n",
    "\n",
    "print(len(X_train_category_df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = []\n",
    "x_trains = []\n",
    "\n",
    "print('Extracting features from the training data using a sparse vectorizer')\n",
    "t0 = time()\n",
    "for i in range(number_of_cats):\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "    x_train = vectorizer.fit_transform(X_train_category_df_list[i]['total_text'])\n",
    "    vectorizers.append(vectorizer)\n",
    "    x_trains.append(x_train)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs\" % (duration))    \n",
    "# print(\"n_samples: %d, n_features: %d\" % x_train.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tests = []\n",
    "\n",
    "print('Extracting features from the testing data using a sparse vectorizer')\n",
    "t0 = time()\n",
    "for i in range(number_of_cats):\n",
    "    x_test = vectorizers[i].transform(X_test_category_df_list[i]['total_text'])\n",
    "    x_tests.append(x_test)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs\" % (duration))    \n",
    "print(\"n_samples: %d, n_features: %d\" % x_train.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #############################################################################  \n",
    "# Benchmark classifiers                                                          \n",
    "def fit_and_benchmark(clf, X_train, y_train, X_test, y_test, target_names):                                                              \n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "                                                                                 \n",
    "    if hasattr(clf, 'coef_'):                                                    \n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "                                                                                 \n",
    "        if feature_names is not None:                       \n",
    "            print(\"top 10 keywords per class:\")                                  \n",
    "            for i, label in enumerate(target_names):                             \n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "        print()\n",
    "                                                                                 \n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred, target_names=target_names))          \n",
    "                                                                                 \n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))                            \n",
    "                                                                                 \n",
    "    print()                                                                      \n",
    "    clf_descr = str(clf).split('(')[0]                                           \n",
    "    print(clf_descr, score, train_time, test_time)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = VotingClassifier(estimators=[\n",
    "#     ('rc', RidgeClassifier(tol=1e-2)),\n",
    "#     ('perc', Perceptron(n_iter=50)),\n",
    "#     ('pa', PassiveAggressiveClassifier(n_iter=50)),\n",
    "#     ('knn', KNeighborsClassifier(n_neighbors=len(cat1_le.classes_))),\n",
    "#     ('rfc', RandomForestClassifier(n_estimators=100)),\n",
    "#     ('sgd', SGDClassifier(alpha=.0001, n_iter=50, penalty=\"elasticnet\")),\n",
    "#     ('SVC_with_L1', Pipeline([\n",
    "#         ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3))),\n",
    "#         ('classification', LinearSVC(penalty=\"l2\"))]))\n",
    "# ])\n",
    "# clf = VotingClassifier(estimators=[\n",
    "#     ('rc', RidgeClassifier(tol=1e-2)),\n",
    "#     ('perc', Perceptron(n_iter=50)),\n",
    "#     ('pa', PassiveAggressiveClassifier(n_iter=50))\n",
    "# ])\n",
    "def create_classifiers(number_of_cats):\n",
    "    for i in range(number_of_cats):\n",
    "        clf = VotingClassifier(estimators=[\n",
    "            ('rc', RidgeClassifier(tol=1e-2))\n",
    "        ])\n",
    "        yield clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # load the csv and the model\n",
    "# from sklearn.externals import joblib\n",
    "# clfs= [0, 0, 0]\n",
    "# clfs[0] = joblib.load('data/mercari/clf_0.pkl')\n",
    "# clfs[1] = joblib.load('data/mercari/clf_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "# t0 = time()\n",
    "# i = 0\n",
    "# for clf in create_classifiers(1):\n",
    "#     clf.fit(x_trains[2], y_train_category_df_list[2])\n",
    "#     pred = clf.predict(x_tests[2])\n",
    "#     score = metrics.accuracy_score(y_test, pred)\n",
    "#     print(\"accuracy:   %0.3f\" % score)\n",
    "                                                                                 \n",
    "#     print(\"classification report:\")\n",
    "#     print(metrics.classification_report(y_test, pred, target_names=target_names))          \n",
    "                                                                                 \n",
    "#     print(\"confusion matrix:\")\n",
    "#     print(metrics.confusion_matrix(y_test, pred)) \n",
    "#     clf = fit_and_benchmark(clf, \n",
    "#                             x_trains[2], y_train_category_df_list[2], \n",
    "#                             x_tests[2], y_test_category_df_list[2], \n",
    "#                             train_cat_transforms[i].classes_)\n",
    "#     i += 1\n",
    "#     joblib.dump(clf, 'data/mercari/clf_{}.pkl'.format(i))\n",
    "# classification_time = time() - t0\n",
    "# print(\"classifiction time:  %0.3fs\" % classification_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1180966, 180315)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trains[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1180966, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_category_df_list[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot go features so we will try PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "VotingClassifier(estimators=[('rc', RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.01))],\n",
      "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "t0 = time()\n",
    "i = 2\n",
    "clfs = [clf for clf in create_classifiers(3)]\n",
    "clf = fit_and_benchmark(clfs[i], \n",
    "                        x_trains[i], y_train_category_df_list[i], \n",
    "                        x_tests[i], y_test_category_df_list[i], \n",
    "                        train_cat_transforms[i].classes_)\n",
    "joblib.dump(clf, 'data/mercari/clf_{}.pkl'.format(i))\n",
    "classification_time = time() - t0\n",
    "print(\"classifiction time:  %0.3fs\" % classification_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "VotingClassifier(estimators=[('rc', RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.01))],\n",
      "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 176.699s\n",
      "test time:  2.634s\n",
      "accuracy:   0.866\n",
      "classification report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                             0.95      0.95      0.95     41574\n",
      "                Beauty       0.93      0.95      0.94     24394\n",
      "           Electronics       0.62      0.30      0.41      6152\n",
      "              Handmade       0.81      0.78      0.79     13691\n",
      "                  Home       0.85      0.81      0.83     34146\n",
      "                  Kids       0.83      0.64      0.72     18931\n",
      "                   Men       0.78      0.60      0.68      9163\n",
      "                 Other       0.73      0.49      0.59      5006\n",
      "     Sports & Outdoors       0.66      0.38      0.49      9181\n",
      "Vintage & Collectibles       0.86      0.97      0.91    133004\n",
      "\n",
      "           avg / total       0.86      0.87      0.86    295242\n",
      "\n",
      "confusion matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 10, does not match size of target_names, 11\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 39540     30     23    282    109     53    241     16     12   1268]\n",
      " [    65  23185     36     60    229     44    109     69     40    557]\n",
      " [   113     50   1876    291    549     89    249     85    143   2707]\n",
      " [   510     77    156  10653    463     39    219     68    227   1279]\n",
      " [   214    237    179    342  27594    427    209    116    897   3931]\n",
      " [    62    112     27     38    252  12044     23    217     61   6095]\n",
      " [   485    253    289    430    484     83   5526     69    163   1381]\n",
      " [    57    121     98    164    401    425     74   2467    137   1062]\n",
      " [    86    601     96    739   1412    147    214     73   3533   2280]\n",
      " [   513    180    263    209    839   1166    201    179    140 129314]]\n",
      "\n",
      "VotingClassifier 0.866177576361 176.6992757320404 2.6343038082122803\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "VotingClassifier(estimators=[('rc', RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.01))],\n",
      "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1917.514s\n",
      "test time:  3.523s\n",
      "accuracy:   0.764\n",
      "classification report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 113, does not match size of target_names, 114\n",
      "  .format(len(labels), len(target_names))\n",
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                                0.54      0.45      0.49      1687\n",
      "              Accessories       0.57      0.21      0.31      1250\n",
      "                  Antique       0.54      0.06      0.11       573\n",
      "                  Apparel       0.60      0.21      0.31       120\n",
      "                      Art       0.59      0.47      0.52       245\n",
      "                  Artwork       0.74      0.83      0.78     26906\n",
      "         Athletic Apparel       0.68      0.42      0.52       501\n",
      "               Automotive       0.35      0.03      0.05      1294\n",
      "          Bags and Purses       0.67      0.58      0.62       264\n",
      "                     Bath       0.67      0.57      0.62      1547\n",
      "              Bath & Body       0.68      0.31      0.42       155\n",
      "      Bathing & Skin Care       0.70      0.82      0.76       846\n",
      "                  Bedding       1.00      0.07      0.12        15\n",
      "    Blazers & Sport Coats       0.71      0.54      0.61       314\n",
      "                     Book       0.74      0.82      0.78      1565\n",
      "                    Books       0.00      0.00      0.00        12\n",
      "          Books and Zines       0.62      0.42      0.50      2939\n",
      "                Boys (4+)       0.68      0.41      0.51      3069\n",
      "            Boys 0-24 Mos       0.72      0.36      0.48      2839\n",
      "               Boys 2T-5T       0.85      0.88      0.87       783\n",
      "    Cameras & Photography       0.00      0.00      0.00        17\n",
      "                  Candles       0.76      0.53      0.62        99\n",
      "   Car Audio, Video & GPS       0.66      0.68      0.67       177\n",
      "  Car Seats & Accessories       0.90      0.92      0.91     10530\n",
      "Cell Phones & Accessories       0.00      0.00      0.00        16\n",
      "     Ceramics and Pottery       0.52      0.06      0.10       247\n",
      "                 Children       0.75      0.73      0.74       485\n",
      "        Cleaning Supplies       0.44      0.23      0.30      1651\n",
      "                 Clothing       0.68      0.74      0.71      3714\n",
      "          Coats & Jackets       0.54      0.29      0.38      1090\n",
      "             Collectibles       0.79      0.82      0.80      1501\n",
      "      Computers & Tablets       0.40      0.06      0.11        32\n",
      "                  Crochet       0.68      0.71      0.70      2305\n",
      "     Daily & Travel items       0.84      0.91      0.88       728\n",
      "                Diapering       0.00      0.00      0.00         8\n",
      "     Dolls and Miniatures       0.79      0.90      0.84      9253\n",
      "                  Dresses       0.29      0.00      0.01       515\n",
      "              Electronics       0.72      0.66      0.69      1556\n",
      "                 Exercise       0.56      0.46      0.50      1254\n",
      "                 Fan Shop       0.77      0.75      0.76       906\n",
      "                  Feeding       0.56      0.74      0.64       106\n",
      "                 Footwear       0.83      0.83      0.83      4833\n",
      "                Fragrance       0.50      0.09      0.15        35\n",
      "                Furniture       0.75      0.43      0.55       643\n",
      "                     Gear       0.89      0.33      0.48        24\n",
      "                  Geekery       0.65      0.34      0.44      3011\n",
      "               Girls (4+)       0.64      0.54      0.59      3498\n",
      "           Girls 0-24 Mos       0.62      0.41      0.49      3646\n",
      "              Girls 2T-5T       0.63      0.23      0.33       106\n",
      "                    Glass       0.67      0.66      0.66       158\n",
      "                     Golf       0.85      0.84      0.84      1611\n",
      "                Hair Care       0.72      0.39      0.51       109\n",
      "       Health & Baby Care       0.00      0.00      0.00        71\n",
      "                 Holidays       0.59      0.55      0.57       525\n",
      "          Home Appliances       0.00      0.00      0.00       102\n",
      "               Home Decor       0.67      0.72      0.70      5030\n",
      "               Home Décor       0.41      0.10      0.16       430\n",
      "               Housewares       0.83      0.75      0.79      7218\n",
      "                    Jeans       0.88      0.96      0.92     12099\n",
      "                  Jewelry       0.60      0.07      0.12       136\n",
      "         Kids' Home Store       0.71      0.85      0.77      4441\n",
      "         Kitchen & Dining       0.56      0.25      0.35        36\n",
      "                 Knitting       0.48      0.54      0.51        41\n",
      "                Magazines       0.90      0.95      0.92     24863\n",
      "                   Makeup       0.83      0.69      0.76       650\n",
      "                Maternity       0.87      0.87      0.87      2284\n",
      "                    Media       0.70      0.42      0.53      3757\n",
      "        Men's Accessories       0.74      0.72      0.73       169\n",
      "                    Music       0.76      0.78      0.77       180\n",
      "      Musical instruments       0.57      0.27      0.36        45\n",
      "              Needlecraft       0.68      0.66      0.67       348\n",
      "                  Nursery       0.79      0.80      0.80      2142\n",
      "          Office supplies       0.42      0.07      0.12      4022\n",
      "                    Other       0.62      0.15      0.24        54\n",
      "                   Others       0.64      0.58      0.61       858\n",
      "                 Outdoors       0.68      0.25      0.37      1852\n",
      "                    Pants       0.60      0.09      0.15        35\n",
      "           Paper Ephemera       0.58      0.71      0.64      1231\n",
      "              Paper Goods       0.50      0.46      0.48        39\n",
      "                 Patterns       0.67      0.63      0.65       811\n",
      "             Pet Supplies       0.50      0.06      0.11        51\n",
      "                     Pets       0.72      0.70      0.71        33\n",
      "           Potty Training       0.85      0.70      0.77       169\n",
      "    Pregnancy & Maternity       0.00      0.00      0.00        10\n",
      "                   Quilts       0.82      0.68      0.74        87\n",
      "                   Safety       0.63      0.25      0.36      1007\n",
      "           Seasonal Décor       0.54      0.42      0.47       384\n",
      "                  Serving       0.82      0.97      0.89     20285\n",
      "                    Shoes       0.63      0.19      0.29       301\n",
      "                   Shorts       0.76      0.77      0.77      5931\n",
      "                Skin Care       0.77      0.85      0.81      2047\n",
      "                   Skirts       0.52      0.44      0.48       575\n",
      "   Storage & Organization       0.77      0.86      0.81        80\n",
      "                Strollers       1.00      0.12      0.22        16\n",
      "                    Suits       0.71      0.69      0.70       389\n",
      "          Suits & Blazers       0.55      0.27      0.36       225\n",
      "                 Supplies       0.67      0.82      0.73      7144\n",
      "                 Sweaters       0.60      0.05      0.10      1621\n",
      "         Sweats & Hoodies       0.84      0.87      0.85      3838\n",
      "                 Swimwear       0.73      0.76      0.75      1810\n",
      " TV, Audio & Surveillance       0.78      0.46      0.58       417\n",
      "              Team Sports       0.75      0.64      0.69      2691\n",
      "      Tools & Accessories       0.68      0.42      0.52      4224\n",
      "                     Tops       0.70      0.86      0.77     21606\n",
      "           Tops & Blouses       0.50      0.22      0.30      1376\n",
      "                      Toy       0.71      0.82      0.76     11557\n",
      "                     Toys       0.75      0.84      0.79      1307\n",
      "            Trading Cards       0.84      0.88      0.86      6772\n",
      "                Underwear       0.88      0.95      0.92      7234\n",
      "   Video Games & Consoles       0.49      0.15      0.23       137\n",
      "                 Weddings       0.69      0.79      0.73      8499\n",
      "      Women's Accessories       0.76      0.91      0.82      9141\n",
      "         Women's Handbags       0.00      0.00      0.00        21\n",
      "\n",
      "              avg / total       0.75      0.76      0.74    295242\n",
      "\n",
      "confusion matrix:\n",
      "[[ 766    6    4 ...,  342   37    0]\n",
      " [   4  263    0 ...,   36   10    1]\n",
      " [  95    0   35 ...,   24   17    0]\n",
      " ..., \n",
      " [ 179    2    2 ..., 6721  253    0]\n",
      " [  33    0    3 ...,  220 8278    0]\n",
      " [   0    0    0 ...,    0    0    0]]\n",
      "\n",
      "VotingClassifier 0.76429166582 1917.514145374298 3.5229523181915283\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "VotingClassifier(estimators=[('rc', RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.01))],\n",
      "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/joydeep/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-5627130469a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mx_trains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_category_df_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                             \u001b[0mx_tests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_category_df_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                             train_cat_transforms[i].classes_)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/mercari/clf_{}.pkl'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-4512f48a78c0>\u001b[0m in \u001b[0;36mfit_and_benchmark\u001b[0;34m(clf, X_train, y_train, X_test, y_test, target_names)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train time: %0.3fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n\u001b[1;32m    188\u001b[0m                                                  sample_weight=sample_weight)\n\u001b[0;32m--> 189\u001b[0;31m                 for clf in clfs if clf is not None)\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \"\"\"\n\u001b[1;32m    807\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_type_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    336\u001b[0m                               \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                               \u001b[0mneg_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                               sparse_output=self.sparse_output)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mlabel_binarize\u001b[0;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msparse_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;31m##############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1007\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.externals import joblib\n",
    "# t0 = time()\n",
    "# i = 0\n",
    "# for clf in create_classifiers(number_of_cats):\n",
    "#     clf = fit_and_benchmark(clf, \n",
    "#                             x_trains[i], y_train_category_df_list[i], \n",
    "#                             x_tests[i], y_test_category_df_list[i], \n",
    "#                             train_cat_transforms[i].classes_)\n",
    "#     i += 1\n",
    "#     joblib.dump(clf, 'data/mercari/clf_{}.pkl'.format(i))\n",
    "# classification_time = time() - t0\n",
    "# print(\"classifiction time:  %0.3fs\" % classification_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifiers saved: 3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"classifiers saved: $(ls data/mercari/clf_* | wc -l)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill the category name for the missing values and build the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['total_text'] = train_df['name'] + \" \" +  train_df['item_description']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['total_text'] = test_df['name'] + \" \" +  test_df['item_description']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_with_no_cat_list = []\n",
    "# for i in range(number_of_cats):\n",
    "for i in range(2):\n",
    "    cat_name = 'category_{}'.format(i)\n",
    "    train_df_with_no_cat = train_df[train_df[cat_name].isnull()]\n",
    "    train_df_with_no_cat_list.append(train_df_with_no_cat)\n",
    "    \n",
    "# train_df_with_no_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df_with_no_cat_list = []\n",
    "# for i in range(number_of_cats):\n",
    "for i in range(2):\n",
    "    cat_name = 'category_{}'.format(i)\n",
    "    test_df_with_no_cat = test_df[test_df[cat_name].isnull()]\n",
    "    test_df_with_no_cat_list.append(train_df_with_no_cat)\n",
    "    \n",
    "test_df_with_no_cat_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_and_transform_df(df, cat_name):\n",
    "    new_df = deepcopy(df)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isnull(row[cat_name]):\n",
    "            new_df.loc[index][cat_name] = vectorizer.transform([row['total_text']])\n",
    "        else:\n",
    "            new_df.loc[index][cat_name] = row[cat_name]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_train_dfs = []\n",
    "pred_train_dfs = []\n",
    "\n",
    "for i in range(2):\n",
    "    matrix_train_df = vectorizers[i].transform(train_df_with_no_cat_list[i]['total_text'])\n",
    "    pred_train_df = clfs[i].predict(matrix_train_df)\n",
    "    matrix_train_dfs.append(matrix_train_df)\n",
    "    pred_train_dfs.append(pred_train_df)\n",
    "\n",
    "print(pred_train_dfs[0].shape, train_df_with_no_cat_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_test_dfs = []\n",
    "pred_test_dfs = []\n",
    "\n",
    "for i in range(2):\n",
    "    matrix_test_df = vectorizers[i].transform(test_df_with_no_cat_list[i]['total_text'])\n",
    "    pred_test_df = clfs[i].predict(matrix_test_df)\n",
    "    matrix_test_dfs.append(matrix_test_df)\n",
    "    pred_test_dfs.append(pred_test_df)\n",
    "    \n",
    "print(pred_test_dfs[0].shape, test_df_with_no_cat_list[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill the category_names with the predicted values wherever they are not present. This will be used in further predictions using pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_df.loc[122])\n",
    "for cat_num in range(2):\n",
    "    i = 0\n",
    "    cat_name = 'category_{}'.format(cat_num)\n",
    "    for index, row in train_df_with_no_cat_list[cat_num].iterrows():\n",
    "        train_df.loc[train_df.train_id == index, [cat_name]] = pred_train_dfs[cat_num][i]\n",
    "        i += 1\n",
    "print(train_df.loc[122])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in test_df_with_no_cat.iterrows():\n",
    "    test_df.loc[test_df.test_id == index, ['category_0']] = pred_test_df[i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[train_df['category_0'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now coming to the main part and the main price predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(11, 7), sharex=True)\n",
    "sns.distplot(np.log(train_df['price'].values+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorized error calc\n",
    "def rmsle(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))\n",
    "# Source: https://www.kaggle.com/jpopham91/rmlse-vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('lets see if there are some null values')\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PROCESS CATEGORICAL DATA\n",
    "#print(\"Handling categorical variables...\")\n",
    "def encode_text(column):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(np.hstack([train_df[column], test_df[column]]))\n",
    "    train_df[column+'_index'] = le.transform(train_df[column])\n",
    "    test_df[column+'_index'] = le.transform(test_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.columns.to_series().groupby(train_df.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.select_dtypes(exclude=['float64', 'int64']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('since brand name is not included now so the below code is not really required but keeping it for future consideration')\n",
    "# encode_text('brand_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Category:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "import unicodedata\n",
    "import re\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    #s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def normalizeLine(sentence):\n",
    "    return [normalizeString(s) for s in sentence.split('\\t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareData(lang1,data):\n",
    "    input_cat = Category(lang1)\n",
    "    for sentence in data:\n",
    "        normalize_line = [normalizeString(s) for s in sentence.split('\\t')]\n",
    "        input_cat.addSentence(normalize_line[0])\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_cat.name, input_cat.n_words)\n",
    "    return input_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    #indexes.append(EOS_token)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_fit(column):\n",
    "    raw_text = np.hstack([(train_df[column]).str.lower(), (test_df[column]).str.lower()])\n",
    "    cat1 = prepareData(column,raw_text)\n",
    "    print (\"adding train data\")\n",
    "    train_df[column + '_seq'] = [variableFromSentence(cat1,normalizeLine(sentence.lower())[0]) for sentence in train_df[column]]\n",
    "    print (\"adding test data\")\n",
    "    test_df[column + '_seq'] = [variableFromSentence(cat1,normalizeLine(sentence.lower())[0]) for sentence in test_df[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_fit('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_fit('item_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the csvs\n",
    "train_df.to_csv('data/mercari/train.1.csv')\n",
    "test_df.to_csv('data/mercari/test.1.csv')\n",
    "print('transformed train and test data saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # save the classifiers\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clfs[0], 'data/mercari/clf_0.pkl')\n",
    "joblib.dump(clfs[1], 'data/mercari/clf_1.pkl')\n",
    "print('model is saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the csv and the model\n",
    "clfs= [0, 0]\n",
    "clfs[0] = joblib.load('data/mercari/clf_0.pkl')\n",
    "clfs[1] = joblib.load('data/mercari/clf_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/mercari/train.1.csv')\n",
    "test_df = pd.read_csv('data/mercari/test.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is needed because the dtypes of name_seq and item_description_seq is wrong\n",
    "import ast\n",
    "train_df['name_seq'] = train_df['name_seq'].apply(ast.literal_eval)\n",
    "train_df['item_description_seq'] = train_df['item_description_seq'].apply(ast.literal_eval)\n",
    "test_df['name_seq'] = test_df['name_seq'].apply(ast.literal_eval)\n",
    "test_df['item_description_seq'] = test_df['item_description_seq'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_df['name_seq'] = train_df['name_seq'].apply(lambda x: np.array(x))\n",
    "# train_df['item_description_seq'] = train_df['item_description_seq'].apply(lambda x: np.array(x))\n",
    "# test_df['name_seq'] = test_df['name_seq'].apply(lambda x: np.array(x))\n",
    "# test_df['item_description_seq'] = test_df['item_description_seq'].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_total_text_matrix = vectorizer.transform(train_df['total_text'])\n",
    "test_df_total_text_matrix = vectorizer.transform(test_df['total_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_df[['item_condition_id', 'category_0', 'shipping']]\n",
    "y_train = train_df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Make a matrix out of the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_df[train_df['category_2'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_1 = train_df[['item_condition_id', 'category_0', 'category_1', 'shipping']]\n",
    "y_train_1 = train_df['price']\n",
    "x_test_1 = test_df[['item_condition_id', 'category_0', 'category_1', 'shipping']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EXTRACT DEVELOPTMENT TEST\n",
    "X_dtrain, X_dvalid, y_dtrain, y_dvalid = train_test_split(x_train_1, y_train_1, random_state=123, test_size=0.05)\n",
    "print(X_dtrain.shape, X_dvalid.shape)\n",
    "print(y_dtrain.shape, y_dvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #EXTRACT DEVELOPTMENT TEST\n",
    "# dtrain, dvalid = train_test_split(train_df, random_state=123, train_size=0.99)\n",
    "# print(dtrain.shape)\n",
    "# print(dvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_dtrain = dtrain[['item_condition_id', 'category_name', 'shipping', 'name_seq', 'item_description_seq']]\n",
    "# y_dtrain = dtrain['price']\n",
    "# x_dval = dvalid[['item_condition_id', 'category_name', 'shipping', 'name_seq', 'item_description_seq']]\n",
    "# y_dval = dvalid['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate the RMSLE on the validation data\n",
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_dtrain.as_matrix().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha = .5)\n",
    "reg.fit(X_dtrain, y_dtrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = reg.predict(X_dvalid)\n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('the score got from a simple ridge regression is:')\n",
    "print(rmsle(y_dvalid.as_matrix(), predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_dvalid.as_matrix(), predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_dtrain, y_dtrain)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_dvalid)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_dvalid, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_dvalid, y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(list(X_dvalid.index), y_dvalid,  color='black')\n",
    "plt.plot(list(X_dvalid.index), y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "TIME_STEP= 10            # rnn time step\n",
    "INPUT_SIZE = 1           # rnn input size\n",
    "LR = 0.02                # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dtrain.as_matrix().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show data\n",
    "N = X_dtrain.as_matrix().shape[0]\n",
    "steps = np.linspace(0, np.pi*2, N, dtype=np.float32)\n",
    "x_np = X_dtrain.as_matrix().astype(np.float32)\n",
    "y_np = y_dtrain.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.rnn = torch.nn.RNN(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=32,         # rnn hidden unit\n",
    "            num_layers=1,             # number of rnn layer\n",
    "            batch_first=True,         # input and output will have batch size as 1s dimension, e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        \n",
    "        self.out = torch.nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x, h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "        \n",
    "        outs = []    # save all predictions\n",
    "        for time_step in range(r_out.size(1)):    # calculating output for each time step\n",
    "            outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1), h_state\n",
    "    \n",
    "        # instead, for simplicity, you can replace above codes by follows\n",
    "        # r_out = r_out.view(-1, 32)\n",
    "        # outs = self.out(r_out)\n",
    "        # return outs, h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = RNN()\n",
    "print(rnn)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_state = None # for initial hidden state\n",
    "\n",
    "for step in range(60):\n",
    "    start, end = step * np.pi, (step+1)*np.pi   # time range\n",
    "    # use sin predicts cos\n",
    "    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32)\n",
    "    x_np = X_dtrain.as_matrix().astype(np.float32)\n",
    "    y_np = y_dtrain.as_matrix().astype(np.float32)\n",
    "    \n",
    "#     x = Variable(torch.from_numpy(x_np[np.newaxis, :, np.newaxis]))    # shape (batch, time_step, input_size)\n",
    "#     y = Variable(torch.from_numpy(y_np[np.newaxis, :, np.newaxis]))\n",
    "    x = Variable(torch.from_numpy(x_np))    # shape (batch, time_step, input_size)\n",
    "    y = Variable(torch.from_numpy(y_np))\n",
    "\n",
    "    \n",
    "    prediction, h_state = rnn(x, h_state) # rnn output\n",
    "    # !! next step is important !!\n",
    "    h_state = Variable(h_state.data)        # repack the hidden state, break the connection from last iteration\n",
    "    \n",
    "    loss = loss_func(prediction, y)         # cross entropy loss\n",
    "    optimizer.zero_grad()                   # clear gradients for this training loss\n",
    "    loss.backward()                         # backpropagation, compute gradients\n",
    "    optimizer.step()                        # apply gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POLY_DEGREE = 3\n",
    "W_target = torch.randn(POLY_DEGREE, 1) * 5\n",
    "b_target = torch.randn(1) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(x):\n",
    "    \"\"\"Builds features i.e. a matrix with columns [x, x^2, x^3, x^4].\"\"\"\n",
    "    x_np = X_dtrain.as_matrix().astype(np.float32)\n",
    "    return torch.from_numpy(x_np)\n",
    "#     return torch.cat([x ** i for i in range(1, POLY_DEGREE+1)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Approximated function.\"\"\"\n",
    "    y_n = y_dtrain.as_matrix().astype(np.float32)\n",
    "    return torch.from_numpy(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_desc(W, b):\n",
    "    \"\"\"Creates a string description of a polynomial.\"\"\"\n",
    "    result = 'y = '\n",
    "    for i, w in enumerate(W):\n",
    "        result += '{:+.2f} x^{} '.format(w, len(W) - i)\n",
    "    result += '{:+.2f}'.format(b[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size=32):\n",
    "    \"\"\"Builds a batch i.e. (x, f(x)) pair.\"\"\"\n",
    "    random = torch.randn(batch_size)\n",
    "    x = make_features(random)\n",
    "    y = f(x)\n",
    "    return Variable(x), Variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "fc = torch.nn.Linear(W_target.size(0), 1)\n",
    "\n",
    "for batch_idx in count(1):\n",
    "# for batch_idx in range(1, 1000):\n",
    "    # Get data\n",
    "    batch_x, batch_y = get_batch()\n",
    "\n",
    "    # Reset gradients\n",
    "    fc.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = F.smooth_l1_loss(fc(batch_x), batch_y)\n",
    "    loss = output.data[0]\n",
    "\n",
    "    # Backward pass\n",
    "    output.backward()\n",
    "\n",
    "    # Apply gradients\n",
    "    for param in fc.parameters():\n",
    "        param.data.add_(-0.1 * param.grad.data)\n",
    "\n",
    "    # Stop criterion\n",
    "    if loss < 1e-3:\n",
    "        break\n",
    "\n",
    "print('Loss: {:.6f} after {} batches'.format(loss, batch_idx))\n",
    "print('==> Learned function:\\t' + poly_desc(fc.weight.data.view(-1), fc.bias.data))\n",
    "print('==> Actual function:\\t' + poly_desc(W_target.view(-1), b_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)  # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)  # outut layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)         \n",
    "        # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net(n_feature=3, n_hidden=10, n_output=1)     # define the network\n",
    "print(net)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in range(100):\n",
    "    batch_x, batch_y = get_batch()\n",
    "    prediction = net(batch_x)               # input x and predict based on x\n",
    "    loss = loss_func(prediction, batch_y)   # must be (1. nn output, 2. target)\n",
    "    optimizer.zero_grad()             # clear gradients for next train\n",
    "    loss.backward()                   # backpropagation, compute gradients\n",
    "    optimizer.step()                  # apply gradients\n",
    "    \n",
    "#     if t % 5 == 0:\n",
    "#         # plot and show learning process\n",
    "#         plt.cla()\n",
    "#         plt.scatter(x.data.numpy(), y.data.numpy())\n",
    "#         plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)\n",
    "#         plt.text(0.5, 0, 'Loss=%.4f' % loss.data[0], fontdict={'size': 20, 'color':  'red'})\n",
    "#         plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "prediction = prediction.data.numpy()\n",
    "y_validation = batch_y.data.numpy()\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_validation, prediction))\n",
    "# # Explained variance score: 1 is perfect prediction\n",
    "# print('Variance score: %.2f' % r2_score(y_dvalid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_validation = batch_y.data.numpy()\n",
    "\n",
    "print('the score got from pytorch neural network is:')\n",
    "print(rmsle(y_validation, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://www.kaggle.com/kswamy15/mercari-using-pytorch\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "axes = plt.gca()\n",
    "axes.set_ylim([0,100])\n",
    "plt.scatter(predicted,y_dvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Implement and save submission\n",
    "x_test_1['price'] = reg.predict(x_test_1)\n",
    "x_test_1['test_id'] = test_df['test_id']\n",
    "\n",
    "print('Validation Data Distribution: \\n', x_test_1['price'].value_counts(normalize = True))\n",
    "submit.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submit file\n",
    "submit = x_test_1[['test_id','price']]\n",
    "submit.to_csv(\"data/mercari/sample_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://www.kaggle.com/kswamy15/mercari-using-pytorch\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
